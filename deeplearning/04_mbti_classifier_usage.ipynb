{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from itertools import groupby\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, LSTM, GRU, GlobalAveragePooling1D, Bidirectional, Dropout, BatchNormalization, Input, Conv2D, MaxPool2D, Reshape\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 4491)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 4491, 64)          15050944  \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4491, 64, 1)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4491, 64, 32)      160       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 2245, 32, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2245, 32, 32)      4128      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1122, 16, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 1122, 16, 32)      4128      \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 561, 16, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 561, 16, 32)       4128      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 280, 16, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 280, 16, 32)       4128      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 140, 16, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 140, 16, 32)       4128      \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 70, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 70, 16, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 35, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 35, 16, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 17, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 17, 16, 32)        4128      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 8, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 16, 32)         4128      \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 16, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                32784     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,121,040\n",
      "Trainable params: 15,121,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# load label, tokenizer with max_len, and models\n",
    "label_dict = {'istj': 0, 'isfj': 1, 'infj': 2, 'intj': 3, 'istp': 4, 'isfp': 5, 'infp': 6, 'intp': 7,\n",
    "              'estp': 8, 'esfp': 9, 'enfp': 10, 'entp': 11, 'estj': 12, 'esfj': 13, 'enfj': 14, 'entj': 15}\n",
    "with open('./models/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "max_len = 4491\n",
    "word_index = tokenizer.word_index\n",
    "model = load_model('./models/model_conv_net.h5')\n",
    "model.summary()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 활용시 필요한 함수 정의\n",
    "# 전처리 함수\n",
    "def preprocess_date(line):\n",
    "    pattern = r'-{15}.*-{15}'\n",
    "    return re.sub(pattern, '', line) \n",
    "\n",
    "def preprocess_text(texts):\n",
    "    stop_words = set(stopwords.words('english'))    \n",
    "    texts = texts.apply(lambda x: re.sub(r'@\\w+\\s?', '', x)) # remove usernames\n",
    "    texts = texts.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x)) # remove links\n",
    "    texts = texts.apply(lambda x: x.lower()) # convert to lowercase\n",
    "    texts = texts.apply(lambda x: re.findall(r'\\b\\w+\\b', x)) # split into individual words     \n",
    "    # texts = texts.apply(lambda x: [word for word in x if word not in stop_words]) # remove stop words\n",
    "    return texts\n",
    "\n",
    "# 한->영 함수\n",
    "def translate_text(text, source_language='ko', target_language='en'):\n",
    "    url = 'https://translate.googleapis.com/translate_a/single?client=gtx&sl={}&tl={}&dt=t&q={}'\n",
    "    response = requests.get(url.format(source_language, target_language, text)).json()\n",
    "    try:\n",
    "        translation = response[0][0][0]\n",
    "    except (IndexError, TypeError):\n",
    "        print(f\"Translation failed for text: {text}\")\n",
    "        translation = \"\"\n",
    "    return translation\n",
    "\n",
    "# 텍스트 -> mbti 함수\n",
    "def predict_mbti(text):\n",
    "    texts = preprocess_text(pd.Series([text]))\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequences, verbose=0)[0]\n",
    "    labels = label_dict.keys()\n",
    "    result = {label: prediction[idx] for idx, label in enumerate(labels)}\n",
    "    return result\n",
    "\n",
    "# 카카오톡 대화파일 -> 사용자별 mbti 함수\n",
    "def predict_mbti_kakaotalk(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Remove date and time information\n",
    "    pattern = r'^\\d{4}-\\d{2}-\\d{2}, \\d{1,2}:\\d{2} [APap][Mm] - '\n",
    "    lines = [re.sub(pattern, '', line) for line in lines]\n",
    "    lines = [preprocess_date(line) for line in lines]\n",
    "    \n",
    "    # Get chat room name and saved date\n",
    "    chat_room_name = lines[0].strip()\n",
    "    saved_date = lines[1].strip()\n",
    "    print(f\"Chat Room: {chat_room_name}, Saved Date: {saved_date}\")\n",
    "\n",
    "       # Group messages by user\n",
    "    user_messages = {}\n",
    "    current_user = None\n",
    "    pattern = r'^\\[(.*?)\\] '  # [사용자명] 패턴\n",
    "    time_pattern = r'\\[(오전|오후)\\s\\d+:\\d+\\]\\s'\n",
    "    for line in lines[2:]:\n",
    "        user_match = re.search(pattern, line)\n",
    "        if user_match:\n",
    "            current_user = user_match.group(1)\n",
    "            if current_user not in user_messages:\n",
    "                user_messages[current_user] = []\n",
    "            # Add message after user name\n",
    "            message = re.sub(pattern, '', line).strip()\n",
    "            message = re.sub(time_pattern, '', message)  # Remove time information\n",
    "            user_messages[current_user].append(message)\n",
    "        elif current_user is not None and line.strip() != '':\n",
    "            # Append message to previous user\n",
    "            user_messages[current_user][-1] += ' ' + re.sub(time_pattern, '', line.strip())  # Remove time information\n",
    "\n",
    "    # Translate and predict MBTI for each user\n",
    "    mbti_results = {}\n",
    "    for user, messages in user_messages.items():\n",
    "        print(f\"\\nProcessing messages for user: {user}\")\n",
    "        print(f\"Messages: {messages}\")\n",
    "        translated_messages = [translate_text(message) for message in messages]\n",
    "        prediction = predict_mbti(' '.join(translated_messages))\n",
    "        top_k = sorted(prediction.items(), key=lambda x: x[1], reverse=True)[:]\n",
    "        mbti_results[user] = top_k\n",
    "\n",
    "    # Print MBTI results by user\n",
    "    for user, results in mbti_results.items():\n",
    "        print(f\"{user}: {results}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Room: 현명 님과 카카오톡 대화, Saved Date: 저장한 날짜 : 2023-05-09 16:55:33\n",
      "\n",
      "Processing messages for user: 현명\n",
      "Messages: []\n",
      "\n",
      "Processing messages for user: 김현우\n",
      "Messages: []\n",
      "현명: [('infp', 0.12568401), ('infj', 0.10242531), ('intp', 0.07970657), ('intj', 0.075053334), ('enfj', 0.07170661), ('enfp', 0.07016323), ('isfj', 0.07000509), ('istp', 0.06441566), ('isfp', 0.05745092), ('istj', 0.056164563), ('entp', 0.053523406), ('entj', 0.050036132), ('esfp', 0.046412587), ('esfj', 0.027513064), ('estp', 0.027047968), ('estj', 0.02269149)]\n",
      "김현우: [('infp', 0.12568401), ('infj', 0.10242531), ('intp', 0.07970657), ('intj', 0.075053334), ('enfj', 0.07170661), ('enfp', 0.07016323), ('isfj', 0.07000509), ('istp', 0.06441566), ('isfp', 0.05745092), ('istj', 0.056164563), ('entp', 0.053523406), ('entj', 0.050036132), ('esfp', 0.046412587), ('esfj', 0.027513064), ('estp', 0.027047968), ('estj', 0.02269149)]\n"
     ]
    }
   ],
   "source": [
    "predict_mbti_kakaotalk('./KakaoTalk/KakaoTalk_20230509_1655_31_857_현명.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 성능 개선의 방법\n",
    "# 전처리 고도화\n",
    "# 모델 고도화 (컨볼루션 트랜스포머 완료)\n",
    "# Transformer, BERT (GPT알고리즘) 모형 사용하기 (완료)\n",
    "# 기존 학습되어 있는 언어모델 레이어 불러와서 사용하기\n",
    "\n",
    "# (2) 카카오톡 대화 내용 넣기 (완료)\n",
    "# 번역 (완료)\n",
    "# 복수의 문장이 들어가서 MBTI 출력되게 구현하기 (완료)\n",
    "# 정규화 개선해야함.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Room: 로봇 과제 공지 전달방 님과 카카오톡 대화, Saved Date: 저장한 날짜 : 2023-05-04 12:23:58\n",
      "\n",
      "Processing messages for user: 남다현\n",
      "Messages: ['2. 보드, 노트북, 센서만 제공된다면 추가로 구매할 하드웨어는 150-300 안에서 다 해결될 것 같습니다', '3. 넵!!', '장민준 / 2019145094 / 010-2876-0427 / pawpaw0427@gmail.com', '최서연 / 2019145030 /  010-2127-8361 / seoyeon99@yonsei.ac.kr', '기인호 / 해당없음', '좋은 하루 보내세요!', '오늘 미팅의 경우 대면으로 진행될까요?', '10분 정도 늦게 시작하는걸로 해서 대면으로 진행하는 것은 어떨까요? 번복드려 죄송합니다 😅', '하드웨어 받은 후 정리되는대로 보내드리겠습니다 : )', '--------------- 2023년 3월 21일 화요일 ---------------', '학부 수업 때문에 15시 이후쯤 가능할 것 같습니다! 혹시 이때도 가능하시다면 찾아봬도 될까요?', '저희가 아직 주제를 모두 정하지 못한 상태인지라, 컨셉 관련 키페이퍼&데이터셋 등등 내일 당장 찾아보는 것이 조금 어려울 듯 싶습니다!', '혹시 다음주까지 시간을 가지고 컨셉 확정을 해봐도 될까요?', '주중 업무시간대로 다시 한번 일정 잡아서 바로 톡 드리겠습니다!', '필요 내용은 아래와 같습니다.', '카메라의 경우 로지텍 C920 모델 채택 예정이고 마운트 방식은 프린팅 혹은 알루미늄 프로파일로, 아직 미정인 상태입니다.', '팬/틸트의 경우, 아래의 두가지 방법을 논의중에 있습니다. (위고와 미팅 후 결정해야할 것 같습니다!)', '1. 다이나믹셀 + u2d2 모듈 사용 (다이나믹셀, u2d2 키트, 브라켓 구매 필요)', '2. 원격 제어 가능한 팬/틸트 모듈 구매', '지난주에 말씀드렸던 구매 필요 항목들 리스트 송부드립니다~!', '저는 아마 회의 동방에서 참석할 것 같습니다~', '오늘 택배 오후 중으로 받으러 가겠습니다!', '예상보다 배트캠이 생각보다 크고 무거워서 팬틸트 모터 한번 테스트를 해봐야할 것 같습니다!', '그리고 리얼센스 카메라의 경우 중고로 주문을 해주셨나봅니다 ㅎㅎ', '서버 컴 관련해서 질문사항이 있는데요,', '하드웨어 세팅은 우선 있는 부품들로 먼저 구성해두었고, 추가 부품 오고 설계해서 프린팅까지 하면 그때 완성이 될 것 같습니다', '궁금한 점 있으면 바로 톡 드리도록 하겠습니다 : )', '바쁘신 와중 죄송합니다ㅠㅜ', '서버컴 관련해서 질문사항이 있는데요,', '요 며칠 사용을 해봤는데 GPU가 계속 인식이 안돼서 버전 다 확인해보니 CUDNN이 7.5.0이 설치되어있는 것 같습니다!', '수정해서 진행해보겠습니다 !!', '다시 설치해서 진행해보겠습니다 : )', '모터가...확실히 토크가 안될 것 같긴 한데 오늘 오후에 전원 넣어서 돌려보겠습니다!', '--------------- 2023년 4월 24일 월요일 ---------------', '구매 목록에 브라켓을 하나 더 추가적으로 넣어야 할 것 같습니다', '데이터 들어오는 구조 관련해서는 제가 이번주 금요일 안으로 정리하여 전달드리도록 하겠습니다!']\n",
      "\n",
      "Processing messages for user: Seok-Jun Buu\n",
      "Messages: ['어제 보내주신 질문들은 SMI로 잘 전달했습니다~', '1. 주간미팅 시간을 목요일 오후 7시로 하면 어떨까 해요', '다음주 주간미팅 에서 저는', '- 과제 계약 진행상황 (참여연구원 등록 진행상황)', '- SMI에서 회신온 내용 그리고 제가 방문할 일자', '를 말씀드리려 해요', '2. 그리고 질문중에 제가 말씀드릴 수 있는 내용', '- 필요한 하드웨어 결제 방식: 연세대학교 과제 카드 사용, 150-300만원 정도 사용 가능합니다만 추가 필요한 것 있으면 다른 과제에서라도 차출해 올게요 ㅎ (삥땅이나 불법적인 방법 아님)', '아직 하드웨어도 없고 너무 정보가 없어서 여러분들께 과제 관련한 진행상황을 요청할 것은 없지만', '논문을 쓴다는 목표 아래에서 현재 있는 정보들 만으로 라도,', '3. 간단하게 연구 주제나 방법에 대해서 논의해보는게 어떨까요? 이런 연구에 관심있다 를 간략히 제게 알려 주시면 좋을 것 같습니다~~', '--------------- 2023년 3월 13일 월요일 ---------------', '언제가 좋은세요? 저는 월요일 저녁 7시 랩세미나가 매주 있어서 월요일은 안되어요, 화수목금 모두 괜찮습니다~', '2. 로봇, 센서, 노트북 언제든지 가져가면 됨 (제가 가져올게요)', '- SMI 초음파 센서', '- 위고로보틱스 차체', '- 개발용 노트북', '3. 추가 필요한 센서/장비 연대에서 SMI로 목록 보내주시면 사서 배송해줌', '- 라인트레이싱용 카메라', '- 팬/틸트 모터 (e.g. 로보티즈 모터)', '4. 개발환경에 필요한 설비가 너무 커서 전체는 못 옮기지만, 질소누출 모사 장비 하나는 대여 가능, 실험실을 연대에 세팅하면 그것을 참고하여 SMI가 공사함', '5. 딥러닝 학습용 데이터 확보되어 있으니 드리겠음', '--------------- 2023년 3월 15일 수요일 ---------------', '과제 생성단계입니다. 참여연구원으로 등록하려고 하니', '이름/학번/연락처(모바일)/이메일주소 회신주시면 감사하겠습니다~', '--------------- 2023년 3월 16일 목요일 ---------------', 'rms2.yonsei.ac.kr 으로 접속하여 연세포탈 학번 비밀번호로 로그인하시면, 과제 참여 정보를 출력할 수 있는지 확인부탁드리려 합니다', '시스템 엄청 느려요', '이번주에는 아직 장비는 받지 못했으나 잠시 모여서 진행상황 확인하시고 관심있는 연구를 공유하시지요 금내일 7시에 뵈어요~', '--------------- 2023년 3월 17일 금요일 ---------------', '장소는 D916 회의실 입니다', '1. 가져온 장비 전달하기', '2. 세팅할 장소 고민해오기', '3. (여러분께 요청) 각자의 연구 주제를 구체화하기 위해, 비슷한 사례나 최신 사례등의 Key paper 찾아보기 (저도 찾아 공유드릴께요)', '--------------- 2023년 3월 20일 월요일 ---------------', '이번주 금요일에 제가 작년 진행한 과제의 건으로 급하게 회의가 잡히는 바람에... 금요일 저희 주간 미팅에 참여 수가 없는 상황이 되었습니다. ㅠ', '마침 내일 하드웨어를 전달받으러 대전으로 다녀올 거기 때문에 (다녀오자마자 전달해 드릴게요), 이번주 금요일에는 여러분들끼리 하드웨어 상황을 한번 보시고 어떻게 진행하실 지 SW 아키텍쳐나 일정, 역할분배 등을 정리하시면 어떨까 합니다.', '1. SW아키텍쳐 예상도, 컴포넌트 구성 등.', '2. 태스크 A~E 구현을 위해 연구/구현되어야 하는 항목들 정리', '3. 역할분배 및 일정', '정도의 PPT 를 정리해주실 수 있나요? 다음 주 미팅 전으로 준비해주시면 좋을것 같아요. 꼭 PPT 아니더라도 공유 노트나 텍스트 등도 괜찮습니다~~', '논문 미팅은 개별로 준비 되는대로 제게 알려주세요 PPT 완성해서 보내주실 필요 없어요~', '초음파카메라는 세팅해서 택배 보내준다는군요', '--------------- 2023년 3월 23일 목요일 ---------------', 'smi', '1234', '--------------- 2023년 3월 24일 금요일 ---------------', '학년이 높아서 바쁘실 텐데 저랑 미팅하실 때 자료가 완벽해야 한다든가 결과가 있어야 한다든가 할 필요 없어요~ 그거 만드려고 미팅하는거라 생각하시고 편하게 찾아 주심 좋겠습니다... 그럼 좋은 밤 좋은 주말 보내시고 아이디어 생각나는거 있음 언제든 알려 주세요~ 이번주는 토욜도 재실 예정 이에요~', '키워드는 Acoustic classification, continual learning, gradient episodic memory, disentangled representation, triplet network 입니다', 'In-vehicle noise classification is critical for ensuring user comfort and satisfaction. The complex acoustic environment within vehicle cabins, overlapping noise sources, and the introduction of new noise types pose significant challenges. We propose Triplet Loss-based Disentangled Episodic Memory (TLDEM), a novel method for continual in-vehicle noise classification that leverages disentangled representation learning using triplet loss and episodic memory.', \"TLDEM employs triplet loss to learn disentangled feature spaces, enabling the separation of distinct noise sources and enhancing classification performance. The method emphasizes the selection of representative samples for episodic memory storage, improving the model's adaptability and robustness in the presence of new noise classes. Extensive experiments were conducted in a continual learning pipeline, demonstrating TLDEM's ability to maintain high performance in identifying both existing and emerging in-vehicle noise types. We evaluate TLDEM's performance on real-world datasets collected from global motor manufacturers.\", \"In summary, TLDEM offers a scalable and effective solution for continual in-vehicle noise classification, addressing the challenges posed by the complex acoustic environment within vehicle cabins and the introduction of new noise types. The method's disentangled representation learning and representative sample selection contribute to its adaptability and robustness, enabling high continual learning performance in accurately identifying in-vehicle noise.\", '--------------- 2023년 3월 25일 토요일 ---------------', '--------------- 2023년 3월 27일 월요일 ---------------', '저녁 6시 30분 이후에는 미팅하기 어렵다고 합니다', '그래서 낮시간으로 다시 물어볼건데 언제가 좋으세요', '누가 참여하시나요? 필요한 내용 정리해 주시면 제가 미리 위고한테 리스트 발송할게요~', '--------------- 2023년 3월 28일 화요일 ---------------', 'smi는 지금 퇴근해버려서 내일이나 대응할것 같아요', '다현씨: 연속학습', '주제로 아이디어가 정제될 것 같고, 서연씨하고 인호씨 어떤 연구 생각하고 계신가 싶어 보냈습니다~', '--------------- 2023년 3월 30일 목요일 ---------------', '--------------- 2023년 3월 31일 금요일 ---------------', '다현씨한테 드린 continual learning 기본 코드 처럼', 'diffusion model 기본 코드 만들어서 발송드려요', '이거를 저희 데이터셋에 적용하는 것 만으로도 충분히 논문이 될 거고, 추가로 아이디어 내어서 개선하는 것도 좋을거 같네요', '인호씨도 continual learning 을 주제로 잡았기 때문에', '저희 팀 연구 목적으로는 두 파트로 나누면 좋을거 같아요', 'continual learning: 다현씨, 인호씨', 'diffusion model (gen. AI): 서연씨, 민준씨', '--------------- 2023년 4월 3일 월요일 ---------------', '--------------- 2023년 4월 4일 화요일 ---------------', 'Cotinual learning - Triplet network 구현해 제안드림 (다현)', '이어서 인호씨께 제안드려요', 'Few-shot learning 주제에서, Prototypical network 입니다.', '구현 완료했기 때문에 의향 있음 시작하기 쉬울 거에요', '키페이퍼 먼저 발송드려요~~', '--------------- 2023년 4월 5일 수요일 ---------------', '--------------- 2023년 4월 6일 목요일 ---------------', '오늘 미팅에 제 주요 목적중 하나는 논문 레이아웃 잡는 것입니다. 다행히도 세개의 튜토리얼 코드가 있기 때문에 그걸 설명드릴거고, 각자 레이아웃 잡으면서 논의해 보아요', '카드 들고 도서관아래 kt 방문하셔야 할꺼에요 카드를 기계 위에 얹어서 뭔가 하더라구요', '--------------- 2023년 4월 7일 금요일 ---------------', '--------------- 2023년 4월 10일 월요일 ---------------', '이제 뱃캠이랑 렌즈 오면 다온건가요?', '인식 코드 완료하였습니다~~', '휴대폰 카메라로 20장 찍어 학습시켰는데 되긴 되는군요 ㅎㅎ', '좀 걱정이 덜해집니다', 'Dynamic Delay Optimization for In-Vehicle Noise Classification Using Reinforcement Learning-Based Beamforming Neural Networks', 'Abstract: In-vehicle noise classification is a challenging task due to the small and enclosed space of the vehicle, which can lead to reverberation and refraction of sound waves. To address this challenge, we propose a novel approach for improving the DOA function in beamforming neural networks for in-vehicle noise classification. Specifically, our approach dynamically optimizes the delay parameter for each input data using Deep Q-Network (DQN)-based reinforcement learning, allowing the network to better adapt to the changing acoustic conditions within each data. This dynamic tuning enables the network to capture and enhance the relevant acoustic signals while suppressing unwanted noise, improving the accuracy and robustness of in-vehicle noise classification. Importantly, our approach is designed to automatically and dynamically adjust the delay parameter for each input data, allowing for more precise and effective tuning. Our proposed approach has potential applications in various fields that require dynamic tuning of parameters, and we believe it represents a significant contribution to the field of deep learning-based beamforming with DOA estimation.', 'Abstract: In-vehicle noise classification is a complex task due to the confined and enclosed nature of the vehicle, causing reverberation and refraction of sound waves. To tackle this challenge, we introduce a cutting-edge method for dynamically optimizing the delay association parameter in beamforming neural networks utilized for in-vehicle noise classification. Our approach harnesses the power of Deep Q-Network (DQN) reinforcement learning to intelligently adjust the delay parameter for each input data, enabling the network to adapt to varying acoustic conditions and mitigate the impact of reverberation and noise refraction. This dynamic tuning process allows the network to emphasize relevant acoustic signals while attenuating undesired noise, significantly enhancing the accuracy and robustness of in-vehicle noise classification. A key feature of our method is its ability to autonomously and dynamically fine-tune the delay parameter for each input data, paving the way for precise and efficient parameter optimization. Our pioneering approach holds promising potential for various applications in domains requiring dynamic parameter tuning and signifies a substantial advancement in the realm of deep learning-based beamforming and DOA estimation.', '--------------- 2023년 4월 13일 목요일 ---------------', '--------------- 2023년 4월 14일 금요일 ---------------', 'IP: 165.132.105.165, Port: 22', 'Username: sclab_guest', 'PW: guest3877', 'CUDNN: 8.1.1', '--------------- 2023년 4월 15일 토요일 ---------------', '--------------- 2023년 4월 17일 월요일 ---------------', '--------------- 2023년 4월 19일 수요일 ---------------', 'pip install tensorflow-gpu=2.9 요런 식으로 하셨나요? 이전 버전이 깔리면서 CUDA가 옛날꺼까지 깔린거일 수 있어요', 'conda activate dahyun 하고 나면', '기본 ~/.bashrc 가 아니라 anaconda 폴더 안의 ~/.bashrc 가 잡히는거 같아요.', '즉 요럴때는 anaconda 폴더 안의 dahyun 환경 안의 ~/.bashrc 에 수동으로 CUDA CUDNN 패스틀 추가해줘야 할 것 같아요~~ 위에 제가 보낸 링크 보면, ~/.bashrc 수정 방법이 있는데요, anaconda3 폴더 안의 dahyun 가상환경 안의 .bashrc 에다가 수정해보시겠어요?', '안되면 다시 알려주세요~~', '--------------- 2023년 4월 20일 목요일 ---------------', '--------------- 2023년 4월 21일 금요일 ---------------', '--------------- 2023년 4월 25일 화요일 ---------------', '--------------- 2023년 4월 27일 목요일 ---------------', '--------------- 2023년 4월 28일 금요일 ---------------', '--------------- 2023년 5월 2일 화요일 ---------------', '제가 오늘 5층가서 코드를 보고 왔는데, 웹소켓 에다가 루프 걸려있으니까 제가 쉽사리 빼낼 수가 없는 구조더라구요. 그래서 SMI 측으로 메일은 보내 두었습니다', '이번주는 저장 스크립트가 목적인데 SMI의 협조 없이는 수행이 불가능하니,', '목요일에 늦게 만나뵈어도 따로 할 얘기가 없어보입니다.', '그래서 이번주는 정기 미팅 대신에 개별로 논문미팅으로 전환해서', '필요한 분들 논문진도내는거에 집중할까 합니다~~', '어떠신가요??', '이번주 미팅은 없는 걸로 할까요!', '쉬면서 논문 구체화도 한번 생각해 보시고요~', '--------------- 2023년 5월 3일 수요일 ---------------', '--------------- 2023년 5월 4일 목요일 ---------------', '어제는 SMI 연구원하고 다현씨하고 메일 주고 받고 저장 스크립트도 일부분 해결 되었어요', '이제 제가 데이터 들어오는 구조 보고, 데이터 모아서 모델 학습시키고, Yolo처럼 실행할 수 있는 형태로 드리면 되기 때문에 여러분들은 이번주에 푹 쉬시고 다음주에 만났으면 좋겠어요~~']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing messages for user: 최서연\n",
      "Messages: ['--------------- 2023년 4월 1일 토요일 ---------------', '1. 배트캠 ip를 할당해줄 공유기가 필요합니다.', '2. 10AWG 사이즈의 커넥터가 추가로 필요할 것 같습니다.', '--------------- 2023년 4월 23일 일요일 ---------------']\n",
      "\n",
      "Processing messages for user: 장민준\n",
      "Messages: ['--------------- 2023년 4월 11일 화요일 ---------------', '해당 websocket server를 서버컴퓨터에서 실행하고 로봇의 nuc에서 서버의 ip를 항햐 str 형태의 데이터를 전달하도록 구성되어 있으며 전달하는 데이터는 entity 추가를 통해 확장 가능하니 필요한 데이터가 생길 때마다 추가하는 방식으로 전개할 수 있을 것이라 생각됩니다.', '사용 방법에 대한 설명은 README에 작성해두었습니다']\n",
      "\n",
      "Processing messages for user: 인호\n",
      "Messages: ['계정 아이디는 smi로 되어있습니다', '--------------- 2023년 3월 29일 수요일 ---------------', '배트캠 팬틸트를 위해서 브라켓을 만들어야합니다', '배트캠 도면이나 치수라도 적힌 자료 아무거나 받아볼 수 있을까요?', '--------------- 2023년 4월 12일 수요일 ---------------', 'scoutmini 제어 코드도 구현하여 마찬가지로 클래스로 만들어 놨습니다', '현재 다현이가 팬틸트 모듈에 대한 클래스 만들고 있으며', 'QR은 팬틸트 브라켓 도착하는대로 팬틸트 코드와 함께 Batcam쪽 클래스로 합칠 예정입니다!']\n",
      "\n",
      "Processing messages for user: 질문 사항\n",
      "Messages: ['- 초기 프로토타입 설계 및 세팅한 업체 (사용 하드웨어 구성도 및 전원분배 관련 정보 필요)', '- 사용 라인트레이싱 알고리즘 및 소스 코드', '- 사용 보드 및 환경 세팅', '- 추가 모터 장착 시 통신 및 전원 분배 방법 (전원소스 및 볼트 상세 내용 필요)', '- 추가 기술 지원이 어느 정도까지 가능한지']\n",
      "남다현: [('infp', 0.11804707), ('infj', 0.11073948), ('intj', 0.09138762)]\n",
      "Seok-Jun Buu: [('infj', 0.19745351), ('infp', 0.10266844), ('intj', 0.097220816)]\n",
      "최서연: [('infp', 0.1256256), ('infj', 0.10244555), ('intp', 0.07968668)]\n",
      "장민준: [('infp', 0.12601842), ('infj', 0.10259603), ('intp', 0.08039405)]\n",
      "인호: [('infp', 0.13517983), ('infj', 0.09930699), ('intj', 0.08479248)]\n",
      "질문 사항: [('infp', 0.12566806), ('infj', 0.10244747), ('intp', 0.07968125)]\n"
     ]
    }
   ],
   "source": [
    "predict_mbti_kakaotalk('./KakaoTalk/KakaoTalk_20230504_1223_50_096_group.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
